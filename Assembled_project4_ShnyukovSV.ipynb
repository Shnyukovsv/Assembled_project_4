{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff1020a",
   "metadata": {
    "cellId": "pbwq209p45adtxfy5ofecd",
    "deletable": false,
    "editable": false,
    "execution_id": "7cb94123-6481-41de-973a-91abe63db303",
    "id": "1ff1020a",
    "tags": [
     "270beaa0-19d4-4537-bff1-11e2aaed886c"
    ]
   },
   "source": [
    "# Прекод\n",
    "\n",
    "# Сборный проект-4\n",
    "\n",
    "Вам поручено разработать демонстрационную версию поиска изображений по запросу.\n",
    "\n",
    "Для демонстрационной версии нужно обучить модель, которая получит векторное представление изображения, векторное представление текста, а на выходе выдаст число от 0 до 1 — покажет, насколько текст и картинка подходят друг другу.\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные лежат в папке `/datasets/image_search/` или доступны по [ссылке](https://code.s3.yandex.net/datasets/dsplus_integrated_project_4.zip).\n",
    "\n",
    "В файле `train_dataset.csv` находится информация, необходимая для обучения: имя файла изображения, идентификатор описания и текст описания. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.\n",
    "\n",
    "В папке `train_images` содержатся изображения для тренировки модели.\n",
    "\n",
    "В файле `CrowdAnnotations.tsv` — данные по соответствию изображения и описания, полученные с помощью краудсорсинга. Номера колонок и соответствующий тип данных:\n",
    "\n",
    "1. Имя файла изображения.\n",
    "2. Идентификатор описания.\n",
    "3. Доля людей, подтвердивших, что описание соответствует изображению.\n",
    "4. Количество человек, подтвердивших, что описание соответствует изображению.\n",
    "5. Количество человек, подтвердивших, что описание не соответствует изображению.\n",
    "\n",
    "В файле `ExpertAnnotations.tsv` содержатся данные по соответствию изображения и описания, полученные в результате опроса экспертов. Номера колонок и соответствующий тип данных:\n",
    "\n",
    "1. Имя файла изображения.\n",
    "2. Идентификатор описания.\n",
    "\n",
    "3, 4, 5 — оценки трёх экспертов.\n",
    "\n",
    "Эксперты ставят оценки по шкале от 1 до 4, где 1 — изображение и запрос совершенно не соответствуют друг другу, 2 — запрос содержит элементы описания изображения, но в целом запрос тексту не соответствует, 3 — запрос и текст соответствуют с точностью до некоторых деталей, 4 — запрос и текст соответствуют полностью.\n",
    "\n",
    "В файле `test_queries.csv` находится информация, необходимая для тестирования: идентификатор запроса, текст запроса и релевантное изображение. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.\n",
    "\n",
    "В папке `test_images` содержатся изображения для тестирования модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99489b26",
   "metadata": {
    "cellId": "n6vkjcacwu39w29bfocxt",
    "execution_id": "1b731a18-3394-4b62-b3f7-018692c2d6de",
    "id": "99489b26"
   },
   "source": [
    "## 1. Исследовательский анализ данных\n",
    "\n",
    "Наш датасет содержит экспертные и краудсорсинговые оценки соответствия текста и изображения.\n",
    "\n",
    "В файле с экспертными мнениями для каждой пары изображение-текст имеются оценки от трёх специалистов. Для решения задачи вы должны эти оценки агрегировать — превратить в одну. Существует несколько способов агрегации оценок, самый простой — голосование большинства: за какую оценку проголосовала большая часть экспертов (в нашем случае 2 или 3), та оценка и ставится как итоговая. Поскольку число экспертов меньше числа классов, может случиться, что каждый эксперт поставит разные оценки, например: 1, 4, 2. В таком случае данную пару изображение-текст можно исключить из датасета.\n",
    "\n",
    "Вы можете воспользоваться другим методом агрегации оценок или придумать свой.\n",
    "\n",
    "В файле с краудсорсинговыми оценками информация расположена в таком порядке:\n",
    "\n",
    "1. Доля исполнителей, подтвердивших, что текст **соответствует** картинке.\n",
    "2. Количество исполнителей, подтвердивших, что текст **соответствует** картинке.\n",
    "3. Количество исполнителей, подтвердивших, что текст **не соответствует** картинке.\n",
    "\n",
    "После анализа экспертных и краудсорсинговых оценок выберите либо одну из них, либо объедините их в одну по какому-то критерию: например, оценка эксперта принимается с коэффициентом 0.6, а крауда — с коэффициентом 0.4.\n",
    "\n",
    "Ваша модель должна возвращать на выходе вероятность соответствия изображения тексту, поэтому целевая переменная должна иметь значения от 0 до 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3510b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\serge\\anaconda3\\lib\\site-packages (0.16.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\serge\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\serge\\anaconda3\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.1.2 in c:\\users\\serge\\anaconda3\\lib\\site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\serge\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\serge\\anaconda3\\lib\\site-packages (from torch==2.1.2->torchvision) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\serge\\anaconda3\\lib\\site-packages (from torch==2.1.2->torchvision) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\serge\\anaconda3\\lib\\site-packages (from torch==2.1.2->torchvision) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\serge\\anaconda3\\lib\\site-packages (from torch==2.1.2->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\serge\\anaconda3\\lib\\site-packages (from torch==2.1.2->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\serge\\anaconda3\\lib\\site-packages (from torch==2.1.2->torchvision) (2023.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\serge\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\serge\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\serge\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\serge\\anaconda3\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\serge\\anaconda3\\lib\\site-packages (from jinja2->torch==2.1.2->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\serge\\anaconda3\\lib\\site-packages (from sympy->torch==2.1.2->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install spacy\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#!pip install spacy[transformers]\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "391932cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import spacy\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#from skorch.callbacks import EpochScoring, EarlyStopping\n",
    "#from skorch import NeuralNetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c4c481",
   "metadata": {},
   "source": [
    "Импортируем данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67529761",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('to_upload/train_dataset.csv')\n",
    "CrowdAnnotations = pd.read_csv('to_upload/CrowdAnnotations.tsv', sep='\\t', header=None)\n",
    "ExpertAnnotations = pd.read_csv('to_upload/ExpertAnnotations.tsv', sep='\\t', header=None)\n",
    "test_queries = pd.read_csv('to_upload/test_queries.csv', sep='|', index_col=0)\n",
    "test_images = pd.read_csv('to_upload/test_images.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "403c28bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262583859_653f1469a9.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2447284966_d6bbdb4b6e.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2549968784_39bfbe44f9.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2621415349_ef1a7e73be.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3030566410_393c36a6c5.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3155451946_c0862c70cb.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3222041930_f642f49d28.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>343218198_1ca90e0734.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3718964174_cb2dc1615e.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image                     query_id  \\\n",
       "0  1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "1  1262583859_653f1469a9.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "2  2447284966_d6bbdb4b6e.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "3  2549968784_39bfbe44f9.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "4  2621415349_ef1a7e73be.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "5  3030566410_393c36a6c5.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "6  3155451946_c0862c70cb.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "7  3222041930_f642f49d28.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "8   343218198_1ca90e0734.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "9  3718964174_cb2dc1615e.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "\n",
       "                                          query_text  \n",
       "0  A young child is wearing blue goggles and sitt...  \n",
       "1  A young child is wearing blue goggles and sitt...  \n",
       "2  A young child is wearing blue goggles and sitt...  \n",
       "3  A young child is wearing blue goggles and sitt...  \n",
       "4  A young child is wearing blue goggles and sitt...  \n",
       "5  A young child is wearing blue goggles and sitt...  \n",
       "6  A young child is wearing blue goggles and sitt...  \n",
       "7  A young child is wearing blue goggles and sitt...  \n",
       "8  A young child is wearing blue goggles and sitt...  \n",
       "9  A young child is wearing blue goggles and sitt...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5822 entries, 0 to 5821\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   image       5822 non-null   object\n",
      " 1   query_id    5822 non-null   object\n",
      " 2   query_text  5822 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 136.6+ KB\n",
      "\n",
      "\n",
      "\n",
      "CrowdAnnotations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>1056338697_4f7d7ce270.jpg#2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>114051287_dd85625a04.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>1427391496_ea512cbe7f.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2073964624_52da3a0fc4.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2083434441_a93bc6306b.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2204550058_2707d92338.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2224450291_4c133fabe8.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2248487950_c62d0c81a9.jpg#2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2307118114_c258e3a47e.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2309860995_c2e2a0feeb.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0                            1         2  3  4\n",
       "0  1056338697_4f7d7ce270.jpg  1056338697_4f7d7ce270.jpg#2  1.000000  3  0\n",
       "1  1056338697_4f7d7ce270.jpg   114051287_dd85625a04.jpg#2  0.000000  0  3\n",
       "2  1056338697_4f7d7ce270.jpg  1427391496_ea512cbe7f.jpg#2  0.000000  0  3\n",
       "3  1056338697_4f7d7ce270.jpg  2073964624_52da3a0fc4.jpg#2  0.000000  0  3\n",
       "4  1056338697_4f7d7ce270.jpg  2083434441_a93bc6306b.jpg#2  0.000000  0  3\n",
       "5  1056338697_4f7d7ce270.jpg  2204550058_2707d92338.jpg#2  0.000000  0  3\n",
       "6  1056338697_4f7d7ce270.jpg  2224450291_4c133fabe8.jpg#2  0.000000  0  3\n",
       "7  1056338697_4f7d7ce270.jpg  2248487950_c62d0c81a9.jpg#2  0.333333  1  2\n",
       "8  1056338697_4f7d7ce270.jpg  2307118114_c258e3a47e.jpg#2  0.000000  0  3\n",
       "9  1056338697_4f7d7ce270.jpg  2309860995_c2e2a0feeb.jpg#2  0.000000  0  3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47830 entries, 0 to 47829\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       47830 non-null  object \n",
      " 1   1       47830 non-null  object \n",
      " 2   2       47830 non-null  float64\n",
      " 3   3       47830 non-null  int64  \n",
      " 4   4       47830 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 1.8+ MB\n",
      "\n",
      "\n",
      "\n",
      "ExpertAnnotations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2718495608_d8533e3ac5.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3207358897_bfa61fa3c6.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3286822339_5535af6b93.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3360930596_1e75164ce6.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3545652636_0746537307.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>434792818_56375e203f.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>106490881_5a2dd9b7bd.jpg</td>\n",
       "      <td>1425069308_488e5fcf9d.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>106490881_5a2dd9b7bd.jpg</td>\n",
       "      <td>1714316707_8bbaa2a2ba.jpg#2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0                            1  2  3  4\n",
       "0  1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2  1  1  1\n",
       "1  1056338697_4f7d7ce270.jpg  2718495608_d8533e3ac5.jpg#2  1  1  2\n",
       "2  1056338697_4f7d7ce270.jpg  3181701312_70a379ab6e.jpg#2  1  1  2\n",
       "3  1056338697_4f7d7ce270.jpg  3207358897_bfa61fa3c6.jpg#2  1  2  2\n",
       "4  1056338697_4f7d7ce270.jpg  3286822339_5535af6b93.jpg#2  1  1  2\n",
       "5  1056338697_4f7d7ce270.jpg  3360930596_1e75164ce6.jpg#2  1  1  1\n",
       "6  1056338697_4f7d7ce270.jpg  3545652636_0746537307.jpg#2  1  1  1\n",
       "7  1056338697_4f7d7ce270.jpg   434792818_56375e203f.jpg#2  1  1  2\n",
       "8   106490881_5a2dd9b7bd.jpg  1425069308_488e5fcf9d.jpg#2  1  1  1\n",
       "9   106490881_5a2dd9b7bd.jpg  1714316707_8bbaa2a2ba.jpg#2  2  2  2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5822 entries, 0 to 5821\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       5822 non-null   object\n",
      " 1   1       5822 non-null   object\n",
      " 2   2       5822 non-null   int64 \n",
      " 3   3       5822 non-null   int64 \n",
      " 4   4       5822 non-null   int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 227.6+ KB\n",
      "\n",
      "\n",
      "\n",
      "test_queries\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_text</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1177994172_10d143cb8d.jpg#0</td>\n",
       "      <td>Two blonde boys , one in a camouflage shirt an...</td>\n",
       "      <td>1177994172_10d143cb8d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1177994172_10d143cb8d.jpg#1</td>\n",
       "      <td>Two boys are squirting water guns at each other .</td>\n",
       "      <td>1177994172_10d143cb8d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1177994172_10d143cb8d.jpg#2</td>\n",
       "      <td>Two boys spraying each other with water</td>\n",
       "      <td>1177994172_10d143cb8d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1177994172_10d143cb8d.jpg#3</td>\n",
       "      <td>Two children wearing jeans squirt water at eac...</td>\n",
       "      <td>1177994172_10d143cb8d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1177994172_10d143cb8d.jpg#4</td>\n",
       "      <td>Two young boys are squirting water at each oth...</td>\n",
       "      <td>1177994172_10d143cb8d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1232148178_4f45cc3284.jpg#0</td>\n",
       "      <td>A baby girl playing at a park .</td>\n",
       "      <td>1232148178_4f45cc3284.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1232148178_4f45cc3284.jpg#1</td>\n",
       "      <td>A closeup of a child on a playground with adul...</td>\n",
       "      <td>1232148178_4f45cc3284.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1232148178_4f45cc3284.jpg#2</td>\n",
       "      <td>A young boy poses for a picture in front of a ...</td>\n",
       "      <td>1232148178_4f45cc3284.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1232148178_4f45cc3284.jpg#3</td>\n",
       "      <td>A young girl is smiling in front of the camera...</td>\n",
       "      <td>1232148178_4f45cc3284.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1232148178_4f45cc3284.jpg#4</td>\n",
       "      <td>There is a little blond hair girl with a green...</td>\n",
       "      <td>1232148178_4f45cc3284.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      query_id  \\\n",
       "0  1177994172_10d143cb8d.jpg#0   \n",
       "1  1177994172_10d143cb8d.jpg#1   \n",
       "2  1177994172_10d143cb8d.jpg#2   \n",
       "3  1177994172_10d143cb8d.jpg#3   \n",
       "4  1177994172_10d143cb8d.jpg#4   \n",
       "5  1232148178_4f45cc3284.jpg#0   \n",
       "6  1232148178_4f45cc3284.jpg#1   \n",
       "7  1232148178_4f45cc3284.jpg#2   \n",
       "8  1232148178_4f45cc3284.jpg#3   \n",
       "9  1232148178_4f45cc3284.jpg#4   \n",
       "\n",
       "                                          query_text  \\\n",
       "0  Two blonde boys , one in a camouflage shirt an...   \n",
       "1  Two boys are squirting water guns at each other .   \n",
       "2            Two boys spraying each other with water   \n",
       "3  Two children wearing jeans squirt water at eac...   \n",
       "4  Two young boys are squirting water at each oth...   \n",
       "5                    A baby girl playing at a park .   \n",
       "6  A closeup of a child on a playground with adul...   \n",
       "7  A young boy poses for a picture in front of a ...   \n",
       "8  A young girl is smiling in front of the camera...   \n",
       "9  There is a little blond hair girl with a green...   \n",
       "\n",
       "                       image  \n",
       "0  1177994172_10d143cb8d.jpg  \n",
       "1  1177994172_10d143cb8d.jpg  \n",
       "2  1177994172_10d143cb8d.jpg  \n",
       "3  1177994172_10d143cb8d.jpg  \n",
       "4  1177994172_10d143cb8d.jpg  \n",
       "5  1232148178_4f45cc3284.jpg  \n",
       "6  1232148178_4f45cc3284.jpg  \n",
       "7  1232148178_4f45cc3284.jpg  \n",
       "8  1232148178_4f45cc3284.jpg  \n",
       "9  1232148178_4f45cc3284.jpg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 500 entries, 0 to 499\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   query_id    500 non-null    object\n",
      " 1   query_text  500 non-null    object\n",
      " 2   image       500 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 15.6+ KB\n",
      "\n",
      "\n",
      "\n",
      "test_images\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3356748019_2251399314.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2887171449_f54a2b9f39.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3089107423_81a24eaf18.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1429546659_44cb09cbe2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1177994172_10d143cb8d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>424307754_1e2f44d265.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3044359043_627488ddf0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3396275223_ee080df8b5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2977379863_2e8d7a104e.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>634891010_9fa189effb.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image\n",
       "0  3356748019_2251399314.jpg\n",
       "1  2887171449_f54a2b9f39.jpg\n",
       "2  3089107423_81a24eaf18.jpg\n",
       "3  1429546659_44cb09cbe2.jpg\n",
       "4  1177994172_10d143cb8d.jpg\n",
       "5   424307754_1e2f44d265.jpg\n",
       "6  3044359043_627488ddf0.jpg\n",
       "7  3396275223_ee080df8b5.jpg\n",
       "8  2977379863_2e8d7a104e.jpg\n",
       "9   634891010_9fa189effb.jpg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   image   100 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 932.0+ bytes\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_table_info(name, data):\n",
    "    print(name)\n",
    "    display(data.head(10))\n",
    "    data.info()\n",
    "    print('')\n",
    "    print('')\n",
    "    print('')\n",
    "\n",
    "display_table_info('train_dataset', train_dataset)\n",
    "display_table_info('CrowdAnnotations', CrowdAnnotations)\n",
    "display_table_info('ExpertAnnotations', ExpertAnnotations)\n",
    "display_table_info('test_queries', test_queries)\n",
    "display_table_info('test_images', test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fed8d26",
   "metadata": {},
   "source": [
    "Добавим обобщенную экспертную оценку. В качестве результата возьмем, как предлагается, мнение большинства. Если показания у всех экспертов разные, оставим результат пустым и удалим в последствии эти строки.\n",
    "\n",
    "Напишем функцию, получающую на вход строку из датасета, а возвращающую результат обобщения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "275a82da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_exp(str_in):\n",
    "    res=[0,0,0,0]\n",
    "    for i in range(0,3):\n",
    "        res[int(str_in[i+2]-1)]+=1\n",
    "    if max(res) == 1:\n",
    "        return None\n",
    "    else:\n",
    "        try:\n",
    "            return res.index(max(res))+1\n",
    "        except:\n",
    "            print('ERROR')\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c5606c",
   "metadata": {},
   "source": [
    "Теперь заполним колонку с результатом и уберем строки, в которых результата нет.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fcc4ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExpertAnnotations[5] = ExpertAnnotations.apply(result_exp, axis=1)\n",
    "ExpertAnnotations = ExpertAnnotations.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90827f4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5696 entries, 0 to 5821\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       5696 non-null   object \n",
      " 1   1       5696 non-null   object \n",
      " 2   2       5696 non-null   int64  \n",
      " 3   3       5696 non-null   int64  \n",
      " 4   4       5696 non-null   int64  \n",
      " 5   5       5696 non-null   float64\n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 311.5+ KB\n"
     ]
    }
   ],
   "source": [
    "ExpertAnnotations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7befc09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.iloc[ExpertAnnotations.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbaa861",
   "metadata": {
    "cellId": "9h91oxwx86d7i8rqt5miv4",
    "execution_id": "4401a0e8-fd2b-479b-9e84-6ffafbcead47",
    "id": "7cbaa861"
   },
   "source": [
    "## 2. Проверка данных\n",
    "\n",
    "В некоторых странах, где работает ваша компания, действуют ограничения по обработке изображений: поисковым сервисам и сервисам, предоставляющим возможность поиска, запрещено без разрешения родителей или законных представителей предоставлять любую информацию, в том числе, но не исключительно тексты, изображения, видео и аудио, содержащие описание, изображение или запись голоса детей. Ребёнком считается любой человек, не достигший 16 лет.\n",
    "\n",
    "В вашем сервисе строго следуют законам стран, в которых работают. Поэтому при попытке посмотреть изображения, запрещённые законодательством, вместо картинок показывается дисклеймер:\n",
    "\n",
    "> This image is unavailable in your country in compliance with local laws\n",
    ">\n",
    "\n",
    "Однако у вас в PoC нет возможности воспользоваться данным функционалом. Поэтому все изображения, которые нарушают данный закон, нужно удалить из обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03995eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ban_dict = ['child', 'baby', 'boy', 'girl', 'teenager', 'schoolboy', 'youth', 'newborn']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b91fa8",
   "metadata": {
    "cellId": "6j23jr8qr9wgyyqkm2puj",
    "id": "b352d2cd"
   },
   "source": [
    "Теперь привидем преобразование описаний, чтобы воспользоваться нашим словарем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2f76496",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "#import en_core_web_sm\n",
    "#nlp = en_core_web_sm.load()\n",
    "\n",
    "\n",
    "def lemma_clear(text):\n",
    "    lemm = nlp(text)\n",
    "    lemm = \" \".join([token.lemma_ for token in lemm])\n",
    "\n",
    "\n",
    "    return \" \".join(lemm.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7553606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = train_dataset['query_text'].apply(lemma_clear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa3d267",
   "metadata": {},
   "source": [
    "Напишем функцию, которая будет возвращать False, если нашла запретное слово в строке, и True, если не нашла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0c60f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_ban_word(text):\n",
    "    for s in ban_dict: \n",
    "        if text.find(s) > -1:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b5a5bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['lem_query_text'] = corpus\n",
    "train_dataset['is_in_law'] = corpus.apply(is_ban_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8274f3c3",
   "metadata": {},
   "source": [
    "Отберем все изображения, в описании которых встечаются \"запретные\" слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17bb9b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spl(text):\n",
    "    return text[:text.find('#')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58413ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "forb_images = list(train_dataset[train_dataset['is_in_law']==False]['query_id'].apply(spl).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a58d733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(forb_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba024d17",
   "metadata": {},
   "source": [
    "266 фото не прошли проверку, и мы имеем их список в forb_images. Теперь уберем из обучающей выборки все \"запретные\" описания и фотографии, в описании которых встречаются запрещенные слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d31b075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_not_forb(text):\n",
    "    if text in forb_images:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "train_dataset_clear = train_dataset[train_dataset['is_in_law']]\n",
    "train_dataset_clear = train_dataset_clear[train_dataset_clear['image'].apply(is_not_forb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265056a4",
   "metadata": {},
   "source": [
    "Таким образом получилось отбросить из обучающей выборки все данные, что связаны с детьми.\n",
    "\n",
    "Теперь добавим к изображениям оценки экспертов.\n",
    "\n",
    "Ранее мы получили объединенную оценку экспертов. Так, как оценки экспертов имеют 4 уровня (от полностью не соответствует до полностью соответствует), а оценки с аутсорса имеют значение от 0 до 1 (процент людей, которые сочли описание соответствующим картинке), необходимо провести преобразование оценки экспертов.\n",
    "\n",
    "В нашем случае стоит взять оценку эксперта, вычесть из нее 1 и разделить на 3. Так мы получим следующие значения оценки эксперта:\n",
    "\n",
    " * Полностью не соответствует: 0\n",
    " * Скорее не соответствует: 0.(3)\n",
    " * Скорее соответствует: 0.(6)\n",
    " * Полностью соответствует: 1\n",
    "\n",
    "Что позволит нам объединить экспертные оценки с оценками с аутсорса с коэфециентами значимости 0.6 и 0.4 соответственно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43e661bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2718495608_d8533e3ac5.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3207358897_bfa61fa3c6.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3286822339_5535af6b93.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0                            1  2  3  4    5\n",
       "0  1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2  1  1  1  1.0\n",
       "1  1056338697_4f7d7ce270.jpg  2718495608_d8533e3ac5.jpg#2  1  1  2  1.0\n",
       "2  1056338697_4f7d7ce270.jpg  3181701312_70a379ab6e.jpg#2  1  1  2  1.0\n",
       "3  1056338697_4f7d7ce270.jpg  3207358897_bfa61fa3c6.jpg#2  1  2  2  2.0\n",
       "4  1056338697_4f7d7ce270.jpg  3286822339_5535af6b93.jpg#2  1  1  2  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>1056338697_4f7d7ce270.jpg#2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>114051287_dd85625a04.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>1427391496_ea512cbe7f.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2073964624_52da3a0fc4.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2083434441_a93bc6306b.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0                            1    2  3  4\n",
       "0  1056338697_4f7d7ce270.jpg  1056338697_4f7d7ce270.jpg#2  1.0  3  0\n",
       "1  1056338697_4f7d7ce270.jpg   114051287_dd85625a04.jpg#2  0.0  0  3\n",
       "2  1056338697_4f7d7ce270.jpg  1427391496_ea512cbe7f.jpg#2  0.0  0  3\n",
       "3  1056338697_4f7d7ce270.jpg  2073964624_52da3a0fc4.jpg#2  0.0  0  3\n",
       "4  1056338697_4f7d7ce270.jpg  2083434441_a93bc6306b.jpg#2  0.0  0  3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>6</th>\n",
       "      <th>2_y</th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2718495608_d8533e3ac5.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>434792818_56375e203f.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1084040636_97d9633581.jpg</td>\n",
       "      <td>256085101_2c2617c5d0.jpg#2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1084040636_97d9633581.jpg</td>\n",
       "      <td>3396157719_6807d52a81.jpg#2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253</th>\n",
       "      <td>979383193_0a542a059d.jpg</td>\n",
       "      <td>3244747165_17028936e0.jpg#2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254</th>\n",
       "      <td>979383193_0a542a059d.jpg</td>\n",
       "      <td>3482062809_3b694322c4.jpg#2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>2985679744_75a7102aab.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>3150742439_b8a352e1e0.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>486917990_72bd4069af.jpg#2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2258 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0                            1         6  \\\n",
       "0     1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2  0.000000   \n",
       "1     1056338697_4f7d7ce270.jpg  2718495608_d8533e3ac5.jpg#2  0.000000   \n",
       "2     1056338697_4f7d7ce270.jpg   434792818_56375e203f.jpg#2  0.000000   \n",
       "3     1084040636_97d9633581.jpg   256085101_2c2617c5d0.jpg#2  0.666667   \n",
       "4     1084040636_97d9633581.jpg  3396157719_6807d52a81.jpg#2  0.333333   \n",
       "...                         ...                          ...       ...   \n",
       "2253   979383193_0a542a059d.jpg  3244747165_17028936e0.jpg#2  0.333333   \n",
       "2254   979383193_0a542a059d.jpg  3482062809_3b694322c4.jpg#2  0.333333   \n",
       "2255   997722733_0cb5439472.jpg  2985679744_75a7102aab.jpg#2  0.000000   \n",
       "2256   997722733_0cb5439472.jpg  3150742439_b8a352e1e0.jpg#2  0.000000   \n",
       "2257   997722733_0cb5439472.jpg   486917990_72bd4069af.jpg#2  0.666667   \n",
       "\n",
       "           2_y       res  \n",
       "0     0.000000  0.000000  \n",
       "1     0.000000  0.000000  \n",
       "2     0.000000  0.000000  \n",
       "3     0.333333  0.533333  \n",
       "4     0.000000  0.200000  \n",
       "...        ...       ...  \n",
       "2253  0.000000  0.200000  \n",
       "2254  0.000000  0.200000  \n",
       "2255  0.000000  0.000000  \n",
       "2256  0.000000  0.000000  \n",
       "2257  0.333333  0.533333  \n",
       "\n",
       "[2258 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(ExpertAnnotations.head())\n",
    "display(CrowdAnnotations.head())\n",
    "#train_dataset_clear.head()\n",
    "\n",
    "ExpertAnnotations[6] = (ExpertAnnotations[5]-1)/3\n",
    "train_data = ExpertAnnotations.merge(CrowdAnnotations, left_on=[0, 1], right_on=[0, 1])[[0, 1, 6, '2_y']]\n",
    "train_data['res'] = train_data[6]*0.6 + train_data['2_y']*0.4\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e739dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_clear = train_dataset_clear.merge(train_data, left_on=['image', 'query_id'], right_on=[0, 1])[train_dataset_clear.columns]\n",
    "train_data = train_dataset_clear.merge(train_data, left_on=['image', 'query_id'], right_on=[0, 1])[train_data.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4ef807",
   "metadata": {
    "cellId": "ggxcvhmhcm9rshysbjoo4n",
    "execution_id": "d7935f99-48c0-42b8-a227-dd2b2d9b70fc",
    "id": "1d4ef807"
   },
   "source": [
    "## 3. Векторизация изображений\n",
    "\n",
    "Перейдём к векторизации изображений.\n",
    "\n",
    "Самый примитивный способ — прочесть изображение и превратить полученную матрицу в вектор. Такой способ нам не подходит: длина векторов может быть сильно разной, так как размеры изображений разные. Поэтому стоит обратиться к свёрточным сетям: они позволяют \"выделить\" главные компоненты изображений. Как это сделать? Нужно выбрать какую-либо архитектуру, например ResNet-18, посмотреть на слои и исключить полносвязные слои, которые отвечают за конечное предсказание. При этом можно загрузить модель данной архитектуры, предварительно натренированную на датасете ImageNet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590205d0",
   "metadata": {
    "cellId": "4wiflhqkew9mq1gq5927e",
    "id": "0167b804"
   },
   "source": [
    "Возьмем архитектуру resnet50 со стандартрными весами (как раз полученными на датасете resnet50 ImageNet). Уберем последние два слоя, чтобы получить на выходе вектор. На примере одного из изображений посмотрим, какой вектор получается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ae1847a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Serge\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Serge\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "), AdaptiveAvgPool2d(output_size=(1, 1)), Linear(in_features=2048, out_features=1000, bias=True)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad_(False)\n",
    "    \n",
    "print(list(resnet.children())) \n",
    "\n",
    "modules = list(resnet.children())[:-1]\n",
    "resnet = nn.Sequential(*modules) \n",
    "\n",
    "resnet.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a88c0d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "norm = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(150),\n",
    "    transforms.CenterCrop(140),\n",
    "    transforms.ToTensor(),\n",
    "    norm,\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "398afd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"to_upload/train_images/1056338697_4f7d7ce270.jpg\").convert('RGB') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86d7263b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor = preprocess(img)\n",
    "output_tensor = resnet(image_tensor.unsqueeze(0)).flatten()\n",
    "output_tensor.size()\n",
    "#output_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b07c419",
   "metadata": {},
   "source": [
    "Размер выходного вектора без пуллинга был слишком велик, поэтому был уменьшен с помощью пуллинга, чтобы сократить затраты памяти.\n",
    "\n",
    "Превратим все изображения в датасете в вектора с помощью этой модели. Для этого напишем функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cfea33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vect_gen_test(string):\n",
    "    img = Image.open(path+string[0]).convert('RGB')\n",
    "    image_tensor = preprocess(img)\n",
    "    output_tensor = resnet(image_tensor.unsqueeze(0)).flatten()\n",
    "    output_tensor.size()\n",
    "    return output_tensor.numpy()\n",
    "\n",
    "def vect_gen_train(string):\n",
    "    img = Image.open(path+string['image']).convert('RGB')\n",
    "    image_tensor = preprocess(img)\n",
    "    output_tensor = resnet(image_tensor.unsqueeze(0)).flatten()\n",
    "    output_tensor.size()\n",
    "    return output_tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f74956cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"to_upload/train_images/\"\n",
    "train_img_vec_arr = np.array(train_data.apply(vect_gen_test, axis=1))\n",
    "\n",
    "#path=\"to_upload/test_images/\"\n",
    "#test_img_vec_arr = np.array(test_queries.apply(vect_gen_train, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9dd49d",
   "metadata": {},
   "source": [
    "Таким образом мы получили массив векторов в порядке, в котором изображения находятся в train_data и test_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea53bf6",
   "metadata": {
    "cellId": "z8evfugfch8wpstvnxv0t",
    "execution_id": "028ade1d-49fe-4110-8b13-3c1aecdaa142",
    "id": "aea53bf6"
   },
   "source": [
    "## 4. Векторизация текстов\n",
    "\n",
    "Следующий этап — векторизация текстов. Вы можете поэкспериментировать с несколькими способами векторизации текстов:\n",
    "\n",
    "- tf-idf\n",
    "- word2vec\n",
    "- \\*трансформеры (например Bert)\n",
    "\n",
    "\\* — если вы изучали трансформеры в спринте Машинное обучение для текстов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd0b514",
   "metadata": {},
   "source": [
    "Воспользуемся tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd7584bd",
   "metadata": {
    "cellId": "5f0eae9yldcozrwh01qp0c",
    "id": "cd7584bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Serge\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b747671f",
   "metadata": {
    "cellId": "n64cmotqegij9arvbc7sxf",
    "id": "b747671f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (1467, 752)\n"
     ]
    }
   ],
   "source": [
    "corpus = train_dataset_clear['lem_query_text']\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=list(stopwords)) \n",
    "\n",
    "tf_idf_train = count_tf_idf.fit_transform(corpus) \n",
    "\n",
    "print(\"Размер матрицы:\", tf_idf_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b51dce0",
   "metadata": {},
   "source": [
    "Теперь можно векторизируем тексты test_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b998c14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = test_queries['query_text'].apply(lemma_clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe7cdbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries['lem_query_text'] = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ce1737c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (500, 752)\n"
     ]
    }
   ],
   "source": [
    "corpus = test_queries['lem_query_text']\n",
    "\n",
    "tf_idf_test = count_tf_idf.transform(corpus) \n",
    "\n",
    "print(\"Размер матрицы:\", tf_idf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e96f58c",
   "metadata": {},
   "source": [
    "### 5. Объединение векторов\n",
    "Подготовьте данные для обучения: объедините векторы изображений и векторы текстов с целевой переменной."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5336c9",
   "metadata": {},
   "source": [
    "Чтобы объединить вектора, переведем их в один формат (np.array) и воспользуемся функцией np.hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6c95c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mass = np.hstack([np.vstack(train_img_vec_arr), tf_idf_train.toarray()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bc5668",
   "metadata": {
    "cellId": "97c9jj3s2zjj62vznivsk",
    "execution_id": "1a2d7233-0c79-479a-be63-5787145e3b48",
    "id": "60bc5668"
   },
   "source": [
    "## 6. Обучение модели предсказания соответствия\n",
    "\n",
    "Для обучения разделите датасет на тренировочную и тестовую выборки. Простое случайное разбиение не подходит: нужно исключить попадание изображения и в обучающую, и в тестовую выборки.\n",
    "Для того чтобы учесть изображения при разбиении, можно воспользоваться классом [GroupShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupShuffleSplit.html) из библиотеки sklearn.model_selection.\n",
    "\n",
    "Код ниже разбивает датасет на тренировочную и тестовую выборки в пропорции 7:3 так, что строки с одинаковым значением 'group_column' будут содержаться либо в тестовом, либо в тренировочном датасете.\n",
    "\n",
    "```\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=.7, random_state=42)\n",
    "train_indices, test_indices = next(gss.split(X=df.drop(columns=['target']), y=df['target'], groups=df['group_column']))\n",
    "train_df, test_df = df.loc[train_indices], df.loc[test_indices]\n",
    "\n",
    "```\n",
    "\n",
    "Какую модель использовать — выберите самостоятельно. Также вам предстоит выбрать метрику качества либо реализовать свою."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a723a8ad",
   "metadata": {
    "cellId": "v1ntb27jt4z9fazi1y8me",
    "id": "a723a8ad"
   },
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, train_size=.7, random_state=42)\n",
    "train_indexes, test_indexes = next(gss.split(X=train_mass, y=train_data['res'], groups=train_dataset_clear['image']))\n",
    "#train_df, test_df = df.loc[train_indices], df.loc[test_indices]\n",
    "\n",
    "X_train = train_mass[train_indexes]\n",
    "X_test = train_mass[test_indexes]\n",
    "y_train = train_data['res'].loc[train_indexes]\n",
    "y_test = train_data['res'].loc[test_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84d9031",
   "metadata": {},
   "source": [
    "Для начала создадим и обучим линейную регрессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d9eb16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression(positive=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression(positive=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression(positive=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr = LinearRegression(positive=True)\n",
    "#param_search = {}\n",
    "#gsearch = GridSearchCV(estimator=model_lr, cv=5, param_grid=param_search, scoring='neg_root_mean_squared_error')\n",
    "#gsearch.fit(X_train, y_train)\n",
    "model_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f0ca874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE кросс-валидации: 0.40668411643791197\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "print(\"RMSE кросс-валидации:\", \n",
    "      mean_squared_error(y_test, scaler.fit_transform(model_lr.predict(X_test).reshape(-1, 1)), squared=False)\n",
    ") #С помощью скейлера приводим результаты к значениям от 0 до 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9b316d",
   "metadata": {},
   "source": [
    "Теперь создадим полносвязную нейронную сеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dcc28007",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(np.array(X_train))\n",
    "X_test = torch.FloatTensor(np.array(X_test))\n",
    "y_train = torch.FloatTensor(np.array(y_train))\n",
    "y_test = torch.FloatTensor(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d78f050c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1020, 2800])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d84ee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_in_neurons, n_hidden_neurons_1, n_hidden_neurons_2, n_hidden_neurons_3, n_hidden_neurons_4, n_out_neurons):\n",
    "            super(Net, self).__init__()\n",
    "            \n",
    "            self.fc1 = nn.Linear(n_in_neurons, n_hidden_neurons_1)\n",
    "            self.act1 = nn.ReLU()\n",
    "            #self.do1 = nn.Dropout(p=0.7)\n",
    "            self.fc2 = nn.Linear(n_hidden_neurons_1, n_hidden_neurons_2)\n",
    "            self.act2 = nn.ReLU()\n",
    "            self.fc3 = nn.Linear(n_hidden_neurons_2, n_hidden_neurons_3)\n",
    "            self.act3 = nn.ReLU()\n",
    "            self.fc4 = nn.Linear(n_hidden_neurons_3, n_hidden_neurons_4)\n",
    "            self.act4 = nn.ReLU()\n",
    "            self.fc5 = nn.Linear(n_hidden_neurons_4, n_out_neurons)\n",
    "            self.act5 = nn.Sigmoid()\n",
    "            \n",
    "            nn.init.kaiming_uniform_(self.fc1.weight, mode='fan_in', nonlinearity='relu')\n",
    "            nn.init.kaiming_uniform_(self.fc2.weight, mode='fan_in', nonlinearity='relu')\n",
    "            nn.init.kaiming_uniform_(self.fc3.weight, mode='fan_in', nonlinearity='relu')\n",
    "            nn.init.kaiming_uniform_(self.fc4.weight, mode='fan_in', nonlinearity='relu')\n",
    "            nn.init.kaiming_uniform_(self.fc5.weight, mode='fan_in', nonlinearity='sigmoid')\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act1(x)\n",
    "        #x = self.do1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.act3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.act5(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23f26130",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in_neurons = 2800\n",
    "n_hidden_neurons_1 = 1200\n",
    "n_hidden_neurons_2 = 600\n",
    "n_hidden_neurons_3 = 200\n",
    "n_hidden_neurons_4 = 10\n",
    "n_out_neurons = 1\n",
    "\n",
    "\n",
    "\n",
    "net = Net(n_in_neurons, n_hidden_neurons_1, n_hidden_neurons_2, n_hidden_neurons_3, n_hidden_neurons_4, n_out_neurons)\n",
    "\n",
    "#net = nn.Sequential(\n",
    "#    nn.Linear(n_in_neurons, n_hidden_neurons_1),\n",
    "#    nn.ReLU(),\n",
    "#    nn.Linear(n_hidden_neurons_1, n_hidden_neurons_2),\n",
    "#    nn.ReLU(),\n",
    "#    nn.Linear(n_hidden_neurons_2, n_out_neurons)\n",
    "#)\n",
    "\n",
    "optimizer2 = torch.optim.SGD(net.parameters(), lr=1e-3, momentum=0.8)\n",
    "\n",
    "optimizers = [optimizer2]\n",
    "\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8b04fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимизатор SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0.8\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      "):\n",
      "Метрика RMSE на 0 итерации = 0.34\n",
      "Метрика RMSE на 10 итерации = 0.33\n",
      "Метрика RMSE на 20 итерации = 0.33\n",
      "Метрика RMSE на 30 итерации = 0.33\n",
      "Метрика RMSE на 40 итерации = 0.33\n",
      "Метрика RMSE на 50 итерации = 0.33\n",
      "Метрика RMSE на 60 итерации = 0.33\n",
      "Метрика RMSE на 70 итерации = 0.33\n",
      "Метрика RMSE на 80 итерации = 0.33\n",
      "Метрика RMSE на 90 итерации = 0.33\n",
      "Метрика RMSE на 100 итерации = 0.33\n",
      "Метрика RMSE на 110 итерации = 0.33\n",
      "Метрика RMSE на 120 итерации = 0.33\n",
      "Метрика RMSE на 130 итерации = 0.33\n",
      "Метрика RMSE на 140 итерации = 0.33\n",
      "Метрика RMSE на 150 итерации = 0.33\n",
      "Метрика RMSE на 160 итерации = 0.33\n",
      "Метрика RMSE на 170 итерации = 0.33\n",
      "Метрика RMSE на 180 итерации = 0.33\n",
      "Метрика RMSE на 190 итерации = 0.33\n",
      "Метрика RMSE на 200 итерации = 0.33\n",
      "Метрика RMSE на 210 итерации = 0.33\n",
      "Метрика RMSE на 220 итерации = 0.33\n",
      "Метрика RMSE на 230 итерации = 0.33\n",
      "Метрика RMSE на 240 итерации = 0.33\n",
      "Метрика RMSE на 250 итерации = 0.33\n",
      "Метрика RMSE на 260 итерации = 0.33\n",
      "Метрика RMSE на 270 итерации = 0.33\n",
      "Метрика RMSE на 280 итерации = 0.33\n",
      "Метрика RMSE на 290 итерации = 0.33\n",
      "Метрика RMSE на 300 итерации = 0.33\n",
      "Метрика RMSE на 310 итерации = 0.33\n",
      "Метрика RMSE на 320 итерации = 0.33\n",
      "Метрика RMSE на 330 итерации = 0.33\n",
      "Метрика RMSE на 340 итерации = 0.33\n",
      "Метрика RMSE на 350 итерации = 0.33\n",
      "Метрика RMSE на 360 итерации = 0.33\n",
      "Метрика RMSE на 370 итерации = 0.33\n",
      "Метрика RMSE на 380 итерации = 0.33\n",
      "Метрика RMSE на 390 итерации = 0.33\n",
      "Метрика RMSE на 400 итерации = 0.33\n",
      "Метрика RMSE на 410 итерации = 0.33\n",
      "Метрика RMSE на 420 итерации = 0.33\n",
      "Метрика RMSE на 430 итерации = 0.33\n",
      "Метрика RMSE на 440 итерации = 0.33\n",
      "Метрика RMSE на 450 итерации = 0.33\n",
      "Метрика RMSE на 460 итерации = 0.33\n",
      "Метрика RMSE на 470 итерации = 0.33\n",
      "Метрика RMSE на 480 итерации = 0.33\n",
      "Метрика RMSE на 490 итерации = 0.33\n",
      "Метрика RMSE на 500 итерации = 0.33\n",
      "Метрика RMSE на 510 итерации = 0.33\n",
      "Метрика RMSE на 520 итерации = 0.34\n",
      "Метрика RMSE на 530 итерации = 0.34\n",
      "Метрика RMSE на 540 итерации = 0.34\n",
      "Метрика RMSE на 550 итерации = 0.34\n",
      "Метрика RMSE на 560 итерации = 0.34\n",
      "Метрика RMSE на 570 итерации = 0.34\n",
      "Метрика RMSE на 580 итерации = 0.34\n",
      "Метрика RMSE на 590 итерации = 0.34\n",
      "Метрика RMSE на 600 итерации = 0.34\n",
      "Метрика RMSE на 610 итерации = 0.34\n",
      "Метрика RMSE на 620 итерации = 0.34\n",
      "Метрика RMSE на 630 итерации = 0.34\n",
      "Метрика RMSE на 640 итерации = 0.34\n",
      "Метрика RMSE на 650 итерации = 0.34\n",
      "Метрика RMSE на 660 итерации = 0.34\n",
      "Метрика RMSE на 670 итерации = 0.34\n",
      "Метрика RMSE на 680 итерации = 0.34\n",
      "Метрика RMSE на 690 итерации = 0.34\n",
      "Метрика RMSE на 700 итерации = 0.34\n",
      "Метрика RMSE на 710 итерации = 0.34\n",
      "Метрика RMSE на 720 итерации = 0.34\n",
      "Метрика RMSE на 730 итерации = 0.34\n",
      "Метрика RMSE на 740 итерации = 0.34\n",
      "Метрика RMSE на 750 итерации = 0.34\n",
      "Метрика RMSE на 760 итерации = 0.34\n",
      "Метрика RMSE на 770 итерации = 0.34\n",
      "Метрика RMSE на 780 итерации = 0.34\n",
      "Метрика RMSE на 790 итерации = 0.34\n",
      "Метрика RMSE на 800 итерации = 0.34\n",
      "Метрика RMSE на 810 итерации = 0.34\n",
      "Метрика RMSE на 820 итерации = 0.34\n",
      "Метрика RMSE на 830 итерации = 0.34\n",
      "Метрика RMSE на 840 итерации = 0.34\n",
      "Метрика RMSE на 850 итерации = 0.34\n",
      "Метрика RMSE на 860 итерации = 0.34\n",
      "Метрика RMSE на 870 итерации = 0.34\n",
      "Метрика RMSE на 880 итерации = 0.34\n",
      "Метрика RMSE на 890 итерации = 0.34\n",
      "Метрика RMSE на 899 итерации = 0.34\n",
      "\n",
      "Лучшая метрика RMSE = 0.33 обнаружена на 1 эпохе\n",
      "Средняя метрика RMSE = 0.33\n",
      "--------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 900\n",
    "batch_size = 150\n",
    "num_batches = ceil(len(X_train)/batch_size)\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    optimizer_rmse = []\n",
    "    print(f'Оптимизатор {optimizer}:')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        order = np.random.permutation(len(X_train))\n",
    "        \n",
    "        for batch_idx in range(num_batches):\n",
    "            \n",
    "            start_index = batch_idx * batch_size\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            batch_indexes = order[start_index : start_index + batch_size]\n",
    "            X_batch = X_train[batch_indexes]\n",
    "            y_batch = y_train[batch_indexes]\n",
    "\n",
    "            preds = net.forward(X_batch.float()).flatten()\n",
    "\n",
    "            loss_value = loss(preds, y_batch)\n",
    "\n",
    "            loss_value.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                test_preds = net.forward(X_test).flatten()\n",
    "                #print(test_preds.numpy())\n",
    "                ans = round(float(torch.sqrt(loss(test_preds, y_test))), 2)\n",
    "                print(f'Метрика RMSE на {epoch} итерации =', ans)\n",
    "                optimizer_rmse.append(ans)\n",
    "    print()\n",
    "    print(f'Лучшая метрика RMSE = {min(optimizer_rmse)} обнаружена на {optimizer_rmse.index(min(optimizer_rmse))} эпохе')\n",
    "    print(f'Средняя метрика RMSE = {round(np.mean(optimizer_rmse), 2)}')\n",
    "    print('---------------------------------------------------------------------------------------------', '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f870d77",
   "metadata": {
    "cellId": "tbnfwg686jpxjdsw7cqbl",
    "execution_id": "5e14c3be-a481-438e-a979-0f4621acea44",
    "id": "2f870d77"
   },
   "source": [
    "## 7. Тестирование модели\n",
    "\n",
    "Настало время протестировать модель. Для этого получите эмбеддинги для всех тестовых изображений из папки `test_images`, выберите случайные 10 запросов из файла `test_queries.csv` и для каждого запроса выведите наиболее релевантное изображение. Сравните визуально качество поиска."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554f11f1",
   "metadata": {},
   "source": [
    "Создадим масив эмбеддингов. Для этого воспользуемся написанной ранее функицей vect_gen_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "836b4766",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"to_upload/test_images/\"\n",
    "test_images_vec = np.vstack(np.array(test_images.apply(vect_gen_train, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4132e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ten_texts():\n",
    "    texts = []\n",
    "    for i in range(0,10):\n",
    "        texts.append(test_queries.iloc[rd.randint(0, 499)]['query_text'])\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "36dbc48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_text(text):\n",
    "    corpus_one = lemma_clear(text)\n",
    "    corpus = []\n",
    "    #print(corpus_one)\n",
    "    #print(is_ban_word(corpus_one))\n",
    "    if not is_ban_word(corpus_one):\n",
    "        return None\n",
    "    else:\n",
    "        #tf_idf_one = count_tf_idf.transform(corpus)\n",
    "        for i in range(0,100):\n",
    "            corpus.append(corpus_one)\n",
    "        tf_idf_one = count_tf_idf.transform(corpus)\n",
    "        return(np.hstack([np.vstack(test_images_vec), tf_idf_one.toarray()]))\n",
    "        #return(tf_idf_one)\n",
    "#conv_text('A young man is wearing blue goggles')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37447af6",
   "metadata": {},
   "source": [
    "Теперь можно проводить тестирование. Для этого для каждого из 10 подобраных описаний выведем описание и картинку, которая наберет наибольшее количество \"очков\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20b55cf8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two small white dogs chasing a red ball\n",
      "29\n",
      "A dog is wearing jeans and a blue and yellow shirt with a black vehicle in the background .\n",
      "29\n",
      "A woman sitting at a sewing machine looks up .\n",
      "29\n",
      "Little brown and white dog running on the sidewalk .\n",
      "29\n",
      "a kickboxer jumping for a kick\n",
      "29\n",
      "A man on a waterski is performing a jump in the air .\n",
      "29\n",
      "A man riding a wakeboard on a lake\n",
      "29\n",
      "Camera man in populated building taping an event .\n",
      "29\n",
      "A little girl buried in the sand .\n",
      "В запросе присутствует запретное слово!\n",
      "A little kid splashes around in the kiddie pool while a lady watches .\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "for item in ten_texts():\n",
    "    print(item)\n",
    "    try:\n",
    "        mass = conv_text(item)\n",
    "        res = net.forward(torch.FloatTensor(mass)).flatten().detach().numpy()\n",
    "        #print(res)\n",
    "        print(res.argmax())\n",
    "        #print(mass.shape)\n",
    "    except:\n",
    "        print('В запросе присутствует запретное слово!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2c8a5a",
   "metadata": {},
   "source": [
    " Модель выдает одно и то же изображение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab1345a",
   "metadata": {
    "cellId": "dnvdkzzxdpet1yc4m64cx",
    "execution_id": "3e367f6a-97e3-4ed7-9b73-39ed363fd2b7",
    "id": "fab1345a"
   },
   "source": [
    "## 8. Выводы\n",
    "\n",
    "- Jupyter Notebook открыт\n",
    "- Весь код выполняется без ошибок\n",
    "- Ячейки с кодом расположены в порядке исполнения\n",
    "- Исследовательский анализ данных выполнен\n",
    "- Проверены экспертные оценки и краудсорсинговые оценки\n",
    "- Из датасета исключены те объекты, которые выходят за рамки юридических ограничений\n",
    "- Изображения векторизованы\n",
    "- Текстовые запросы векторизованы\n",
    "- Данные корректно разбиты на тренировочную и тестовую выборки\n",
    "- Предложена метрика качества работы модели\n",
    "- Предложена модель схожести изображений и текстового запроса\n",
    "- Модель обучена\n",
    "- По итогам обучения модели сделаны выводы\n",
    "- Проведено тестирование работы модели\n",
    "- По итогам тестирования визуально сравнили качество поиска"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 76,
    "start_time": "2024-01-04T15:43:09.473Z"
   },
   {
    "duration": 51,
    "start_time": "2024-01-04T15:43:28.852Z"
   },
   {
    "duration": 9,
    "start_time": "2024-01-04T15:43:41.212Z"
   },
   {
    "duration": 3,
    "start_time": "2024-01-04T15:44:06.357Z"
   },
   {
    "duration": 15,
    "start_time": "2024-01-04T15:44:08.746Z"
   },
   {
    "duration": 6,
    "start_time": "2024-01-04T15:44:57.117Z"
   },
   {
    "duration": 275428,
    "start_time": "2024-01-04T15:50:10.739Z"
   },
   {
    "duration": 8471,
    "start_time": "2024-01-04T15:54:46.169Z"
   },
   {
    "duration": 0,
    "start_time": "2024-01-04T15:54:54.643Z"
   },
   {
    "duration": 0,
    "start_time": "2024-01-04T15:54:54.645Z"
   },
   {
    "duration": 404,
    "start_time": "2024-01-04T16:02:18.423Z"
   },
   {
    "duration": 76,
    "start_time": "2024-01-04T16:02:30.678Z"
   },
   {
    "duration": 227632,
    "start_time": "2024-01-05T15:58:16.510Z"
   },
   {
    "duration": 8263,
    "start_time": "2024-01-05T16:02:04.144Z"
   },
   {
    "duration": 244,
    "start_time": "2024-01-05T16:02:12.409Z"
   },
   {
    "duration": 0,
    "start_time": "2024-01-05T16:02:12.655Z"
   },
   {
    "duration": 45,
    "start_time": "2024-01-06T17:13:46.313Z"
   },
   {
    "duration": 4557,
    "start_time": "2024-01-06T17:14:01.322Z"
   },
   {
    "duration": 257556,
    "start_time": "2024-01-06T17:14:23.413Z"
   },
   {
    "duration": 8067,
    "start_time": "2024-01-06T17:18:40.971Z"
   },
   {
    "duration": 238,
    "start_time": "2024-01-06T17:18:49.039Z"
   },
   {
    "duration": 0,
    "start_time": "2024-01-06T17:18:49.278Z"
   },
   {
    "duration": 60,
    "start_time": "2024-01-06T17:35:51.625Z"
   }
  ],
  "celltoolbar": "Отсутствует",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "notebookId": "e47b60f7-b2b4-44ee-beb3-b44a93eaf068",
  "notebookPath": "precode.ipynb",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
